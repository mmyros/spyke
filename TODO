GENERAL:

- WARNING! TODO: not sure if say ADchan 4 will always have a delay of 4us, or only if it's preceded by AD chans 0, 1, 2 and 3 in the channel gain list - I suspect the latter is the case, but right now I'm coding the former

- for convenience in neuropy, copy all stimulus data from .srf to .sort file

- does disabling a channel really prevent it from being searched on?

- think there's an issue with the cursor width not updating when the window it represents (the one to the left) changes its zoom level

- add CSD calculation and display

- just a note: user should probably disable any grounded out chans in the dataframes, before beginning detection/sorting/matching. Any disabled chans in the dataframes should propagate through the whole process as disabled by default (not sure if this is the case right now)

- get tooltips to work on main spyke frame widgets

- make ESC in tree and event list clear the current selection

- when assigning an event to a plot, change the zorder of the lines such that the maxchan is always on top, only really need to deal with the maxchan, which can sometimes be big enough to span over to the screen real estate of other chans
    - can make this a template method too, such that it sets the zorder for all lines in constituent events to be the same as it is for the template mean

- hovering over waveforms should highlight the closest datapoint on the closest chan with a circle point or something, while displaying its time and exact voltage in the tooltip - this would probably be more useful than displaying the voltage in the potentially empty space under the mouse
    - should do this both for spike window and sort window (not really necessary for chart or lfp, might be slow, but might be nice too), although in sort window it wouldn't be clear which waveform to do it on, for overlapping waveforms

- plot and control thresh level on spike and chart plots
    - use picker - when a thresh line is picked (within a tolerance of a couple pix), change mouse cursor to hand or vertical sizer, and while button is down, adjust position of thresh lines and value of the manual thresh level in Events tab

- separate groups of 3 digits in spin edit and end labels with commas (time in us)

- add 1ms wide chart window to sort window, so you can see chan layout of events in both real space and chart space, might make it easier to sort

- combined message and stimulus DIN window:
    - messages: maybe just a combo box with timestamp:message entries. Choosing one of them skips you to that timestamp. Changing current file position with other methods should automatically scroll you through the combo box at appropriate times
    - stimulus din: similar to above: drop down combo box with timestamp:DIN value entries. Again, changing current file position with other methods should automatically scroll you through the combo box at appropriate times

- stop forcing the main window to position itself at (0, 0), check what the upper leftmost available position is - for someone like Nick with the taskbar along the top of the screen, it's more like (0, 30)

- this might speed up plotting even further: have only one actual Plot object per plot panel (the quickRemovePlot), and then another that's just a shell for temporarily holding plot attribs (data, colour, style) which are updated, drawn to buffer, updated, drawn to buffer, etc. and then blitted (this is actually a lot like having axes.hold = True)
    - I think this would vastly reduce the number of Line2D objects needed - initing them takes a long time, and once they've been inited, they sit there taking up memory
    - not sure how this would affect used_plots and available_plots
    - seems like a good solution for overplotting thousands of plots in the error threshold window
        - or maybe better thing there would be to only overplot on top of the template mean say the 10 or 20 events with the highest errors that fall below the current error threshold

------------------------------------
INTERPOLATION

    - when resamplex > 1 and shcorrect == False, you only need resamplex - 1 kernels. You don't need a kernel for the original raw data points. Those won't be shifted, so you can just interleave appropriately

    - take DIN channel into account, might need to shift all highpass chans by 1us, see line 2412 in SurfBawdMain.pas

    - could use speed improvement

    - only bother displaying interpolated data for spike frame - not necessary for chart and lfp frames, and will conserve update speed to a large extent compared to uninterpolated mode

------------------------------------
EVENT DETECTION:

    - LOCKOUT: do I propagate any spatiotemporal lockouts from the end of one searched block to the start of the next?  I'm taking slightly overlapping blocks of data to make sure I don't miss any spikes that fall on the borders, but I'm not sure if I'm propagating lockouts...

    SPIKE MODELLING:

        - except for the initial threshold test, instead of directly checking raw voltage values to see if they exceed certain values and when that occurs (like a window discriminator), how about this:
            - when you find a spot that exceeds the initial threshold, fit a spike model to the signal on that channel and each of the surrounding channels within slock. The spike model will be biphasic (or maybe triphasic). Now, of your modelled channels, find the one with the maxchan at the peak of the initial phase, model any further channels that might fall within the slock of that new maxchan, and search one last time for the maxchan within slock
            - model parameters: overall sign (+ve sign would be say a normal initially downward going spike), overall width (up to 1.5ms say), and amplitude of each phase (phases will be forced to alternate in sign)
            - once you've found your best fit model (which will necessarily be smooth), use it to decide if it qualifies as a spike (ie, use it to check amplitude of its second phase), and if so, to decide how long to lock out for
            - this would be a kind of denoising, and would get around weird cases where the spike is distorted, which if you look at raw values, screws up your decision of where the peaks are and how long to lock out for
                - this would probably get rid of the spike alignment problems when matching templates
            - should the model be a Gaussian windowed polynomial of order nphases + 1?
            - how best to go about actually fitting the model? what's the numpy/scipy algorithm for this?
                - there's scipy.optimize, which has a .leastsq() f'n
                - there's also matplotlib.mlab.polyfit
            - then, if you've decided it qualifies as a spike, you can save the model for it, and use that for template building and matching
        - Nick says: Levenberg-Marquadt algorithm (LMA) is least squares, and so is simplex? What differs is just the cost f'n?
            - ah, scipy.leastsq is LMA
            - Nick: instead of doing template matching after modelling the spike, you can just plot the model parameters in a multidimensional space and do normal clustering - skip the whole matching step!
            - says best to just use sum of Gaussians, no need to multiply a N+1 order polynomial with N gaussians
                - tried this doing some manual fitting, sum of Guassians looks great, and is very malleable to get you the spike shape you want
            - also, in the same go, you can model the position of the spike in space - just add a 2D gaussian model for space (that's another 4 params: two means + two stdevs) - then, when you cluster, you're in a very intuitive space (even if its, say 6+4 = 10 dims) that involves the means, stdevs, and amplitudes of two spike phases, plus the position and spread in space.
                - this brings us all the way back to what was Phil's original idea: use physical space as your clustering space
            - should actually have another param theta for angle of 2D gaussian
        - I should probably try this all out in pure Python to start, including the intial threshold detection step (using dynamic thresholds)
            - nothing in this whole modelling method precludes changing anything about the spatiotemporal lockout - that can stay as is. What changes is that the lockout becomes more accurate, since you're modelling the spike peaks in both space and time, which is less affected by spatiotemporal noise than the raw data values
            - for initial spike detection, instead of just looking back one data point to see if signal is diverging from 0 (which itself is susceptible to noise), maybe look back two or more points, or average across the last two or more points to make that decision - this would make you less susceptible to suspect a spike due to a little mini up-down event on the down slope of the final phase of the previously detected spike
                - or, if you see an up-down event, check if it exists on other chans at the same time - although, this assumes that the spike is multichannel, which it isn't necessarily
            - might also be able to reduce num params by fixing all spike phase gaussian means and stdevs to be the same (assuming S+H correction is turned on, and there aren't any backpropagating spikes)
        - spike at ptc15/87/t=23700, chan=3 could definitely use separate vertical and horizontal spatial sigmas - the vertical one would be greater
            - same goes for spike at ptc15/87/t=21940, chan=10. Maybe sigma vector amplitude and angle would be better
            - having two spatial sigmas probably makes the problem underconstrained for a 2 column probe, but it might work on a 3 column probe - I think Tim concluded this as well
            - problem is that to compensate for something that obviously isn't circularly symmetric in space, it sets the source way off the probe to the left or the right. This then messes with the spatial lockout, which is centered on the modeled source location, so you end up getting double triggers.

        - another strategy might be to give up on the spatial modelling, fix temporal gaussian means and sigmas across chans, but give each chan its own two amplitudes, then just triangulate to find spatial mean, or then run the model in a separate independent run, using the modelled output values in time from the previous run, to decide on the spatial means and sigmas and orientation. This will help prevent some of the parameters from confusing the others. In other words, maybe the first run should be concerned with finding the spike's point in time, and the second run with finding its point in space.

        - maybe I should do the full 3D modelling that Tim did, this would only require adding one extra parameter: z0. sigmaz would be the same as sigmax. Also, maybe theta should just be plugged into the model as a constant, determined by the user, and defaulting to 0
            - might also try a 3D Guassian instead of the 3D 1/r. Gaussian is smoother and well defined around 0, leastsq might be more stable with it

        - could also try feeding just the main peak or the two peak amplitudes of each channel to the spatial model, instead of all the points in the spike. The peak values might be more consistent with the spatial model, and therefore easier to fit and less likely to result in ridiculous spatial parameter outputs
            - benefit: treats normal and backprop APs equally - otherwise a backprop
            - or maybe just fit the biggest abs(peak) instead of both peak and valley, since the two sometimes give conflicting info -- one chan might be max for the first peak, another will be max for the second - see ptc15.87.28880
            - or maybe model both peaks, but in separate runs, and use the results of both runs for clustering

        - better way of dealing with backprop rather than just taking the peak amplitudes, is to leave it full waveform and add an AP velocity parameter (um/us)
            - could assume that propogation delay is up (or along the user-supplied theta), or could have two different delays, one in the x and one in the y direction (probably unnecessary). Either way, the current spike time at the x, y coords of the spatial model would be the 0-point time reference

        - interpolating to 100 kHz would double the number of data points the model could work with - this might make it perform better?

        - should probably initialize model (x0, y0) to weighted spatial mean of chans, instead of just the maxchan coords - this would also help to reduce singularity/differentiability problems with 1/r model

    - could speed things up by only interpolating say each 1ms of data following an initial threshold crossing, maybe interpolate to 100 kHz while we're at it, and leave everything else at 25 kHz without any S+H correction - you don't really need interpolation or S+H correction for the initial threshold detection, I think...


    - for each searchblock() call, I only allocate enough memory to store event times for 54 cells (one per chan) with an average firing rate of 1 kHz - perhaps I should check in the cython code if I'm about to exceed the bounds of the eventtimes array, and grow it when need be, or at least print an error, instead of segfaulting!

    - create a new thread or process for each searchblock() call - not sure if this will help much, cuz I think the slowest part is the loading of waveform data off the disk

    - dynamic spatiotemporal lockout: some spikes span greater space and time than others, yet they're all given the same lockout. I guess on thresh xing and again on finding a spike, you could search locally in time and space and within the fixed slock and tlock, and see if signal drops below thresh in something less than slock and tlock, and adjust the lockout accordingly for that thresh xing or found spike

    - doubleclick detection_list row brings up textctrl in a (modeless?) dialog with entire 2D events array for that item

    - change event array returned by detector.search() to be many rows, two columns, instead of 2 cols, many rows. Would be more natural that way:
        - printouts, no matter how long, would always have maxchan and timepoint right next to each other
        - length checking (of number of events) would only need len, which works on rows

    - maybe consider looking for some kind of multichannel threshold crossing instead of testing each channel separately at the start of the inner loop: if say sum or sumsquared of all chans exceeds some (potentially dynamic) threshold (say 3.5*median for each chan * number of chans), then maybe you've stumbled across some event that's hard to see on a single chan basis, but is more obvious if you squint your eyes and look across a few chans at once (see ptc15/87 @ t=102000520, chans=[30,22,31], most easily visible in chart window)
        - or maybe for each timepoint, grab triplets (or quads or something) of neighbouring channels and look at their sum, instead of the sum for all chans, but then for each timepoint you'd have to do this for all possible neighbouring triplets, which might start getting slow


------------------------------------
TEMPLATES:

    - Nick: add kmeans to quickly generate templates
        - maybe not so hard, since kmeans is built into scipy I think, but it's still going to require arbitrary parameter values that you'll have to set, and it might give you a false sense of completeness/correctness

    - replace event listctrl with a virtual listctrl, for faster populating of (and scrolling through?) many thousands of detected events

    - unsorted event list text background should be coloured according to maxchan
        - second list control below it for trash?

    - hitting ENTER on a single event in event list should seek the dataframes to that timepoint (just as clicking on the event in the sort window does the same, sort of by accident) - right now it toggles selection of currently focused item, as does SPACE

    - subtemplates - recognize that two distinct events might be from the same cell, but in a different mode of operation
    - toggle the display of all the templates (their means) at once (button, or Ctrl-A?), with just their active channels displayed. This way, you can quickly see if some templates are very similar, and how the cells are distributed across the electrode. This also lets you decide which templates need more/fewer channels enabled to help distinguish between them. Each template should be a different colour (up to say 16 or so).


    - MANUAL SPIKE ALIGNMENT/DURATION:

        - activation (double-click/enter) of either an event list item or a tree item will bring up a dialog box (one that doesn't prevent access to its parent while it's open. modeless?) with two spin ctrls which let you set the trange of the event/template. Plots should update dynamically while the dialog is still open.
            - modifying a template's trange should do the same for all its member events
            - modifying the trange of a template's member event should also modify the template's trange and that of all other member events
            - for events, add a 3rd spin ctrl to modify the events .t timestamp, for aligning misaligned spikes (triggered off the wrong phase, etc.). Again, should have this dynamically update the event's plot on every spin ctrl event
                - every time you modify the timestamp to your liking, maybe when you hit OK it should check to make sure you haven't duplicated some other existing event with exactly the same maxchan and timestamp. This can happen if two events which are really one and the same are detected by the detector, and you modify one to match the phase of the other

        - do this on a per spike basis as a feature, if automated alignment can't always get it right
        - when doing alignment on a template, move all member events too. Duh. We'll just be adjusting tref for the template, which should then trigger a re-cut of all member spikes?

        - custom spike duration per template
            - Need to make the spike duration (currently 1ms) user settable for every template. Some spikes are broad, others narrow, and it's best to confine the templates to just those times with useful information about the spike. Otherwise, if there's too much flatline on either side, then you're basically saying "it ain't a spike unless stuff doesn't happen immediately before or after it", which isn't true. You might get a spike very soon after from another cell, or even from the same cell if it's a fast spiker.
            - in other words, we want the ability to crop a template in time. This complements the ability to crop a template in channel space

    - for Sort frame, catch Paint event or whatever so that instead of doing a full redraw after de-occlusion, you just restore the saved .background

    - TODO: yet another wxTreeCtrl | wxTreeMultiple flag bug to report to trac: when moving down from the last tree item, you lose highlight (but not focus). Then when you press up, focus and higlight jump to second last item. Similar situation at the top of the tree.

    - when a combination of templates and events are selected in the tree and you hit Delete, leave the templates selected, and only delete the events
        - this should then update the plots for the templates, because their member spikes have just changed

    - cycle between next/previous set of 10 or so member events for current template (or first selected template) on > and < keypresses. Or maybe + and - keypresses

    - hover over event in tree should give you tooltip with event time and maxchan

    - BUG: after opening a .sort file, if your first click is on the first template, no selection event happens, and template mean isn't plotted. Have to move to another one first, then back. Not a problem if first click is on something other than first template
        - smells like another wxWidgets bug



------------------------------------
MINI MATCH/RIP:

    - while building up templates, have ability to do sort of a mini rip of your current templates across the current subset of spikes.
    - this would allow you to quickly increase the number of spikes in each template, and would reveal which spikes in your subset are still very different from any templates you've generated so far, so you can prioritize and focus on those next
    - more importantly, this will aid in sweeping up spikes from those cells that fire a lot and distract you from those that fire rarely
    - a degenerate version of this would be to do a self rip, where you rip across only the set of spikes that are currently members of the template. This would allow you to adjust the error thresh until the self rip just barely returns all of the current members of the template
    - just as for a normal rip, you'll first need to set an error thresh for the template
    - as you progress in your template building, you can occasionally do a mini rip and look at the error histogram, to see how well that template separates spikes out from the subset. Should be able to adjust the error thresh such that you get exactly the spikes that are already members


------------------------------------
MATCHING/RIPPING:

    - instead of ripping against all the raw data, spike detect the whole file, and then rip against the detected spikes. If you center both your templates and your events on the peak, then comparing a template to an event is a one-shot process - no timeshifting required. 2 benefits:
        - much faster
        - error histograms will be more sharply bimodal, since you're not comparing templates to noise ever, just to events
            - also, no longer have to worry so much about selecting as few flat chans as possible in your template, in the worry that it'll start triggering against flatish lines of noise in the raw data
    - to reduce spike variability due to correlated noise, for any given comparison between template and data (be it against any timepoint in data, or against a detected event), take the channels that aren't selected in the template (purportedly because they have no significant signal on them), and at every timepoint, take their mean, and subtract that from _all_ channels. This should make spikes in the raw data (or in the detected events) look more like one of the templates
        - mean might not be ideal - maybe take their covariance and subtract it or something (see hyperellipsoidal method ref'd in 200x Blanche)
        - this should be done during any comparison between template and data, including during min rips (see below)


------------------------------------
VERIFICATION:

    - after completing a rip of the whole file, assemble the spike times from all the templates into a single list. Compare it to the list of spike times generated by applying the spike detection algorithm to the whole file. See how the two sets of spike times overlap. Imagine a venn diagram: if there are spikes that the detection algorithm found that the MTM algorithm did not find, then you need to examine those spikes. Either:
        A) you set your error thresh too stringently for the template that should have matched that spike;
        B) you have bad templates, or you're missing templates

    - plot autocorrelograms for each template, and cross-correlograms for all template pairs, make sure the bin heights are ~0 for abs(deltaT) < 1ms for autocorrs, make sure you don't have ridiculously huge peaks in xcorrs
        - wasn't there some other related test that we should be doing?
    - Nick: create a distance/similarity metric that, for all pairs of templates, for all overlapping channels, measures the difference between the signals, normalized by, say, the number of overlapping channels and the number of points per channel. This would help confirm that two templates are indeed two separate cells

    - plot spikes as fat bright vertical lines or something underneath the chart window so you can scroll through and see just what was classified as a spike and what wasn't. Vertical line colour should match template colour

    - limit template generation to specific part of file
        - Nick's idea: randomly sample events from, say, only the first 10 minutes of a recording, build up your templates with those. Then, rip across the whole file, and watch if fit gets worse the further away you get in time.
            - plot goodness of fit over time - Goodness of fit might change over time, especially over hours, and in recordings different from which the templates were generated. Either divide each recording up into pieces say 10 minutes long, and plot that, or have a sliding window that calculates the goodness of fit for the last 10 minutes (that would give you lots more data points)


------------------------------------
LOW-PRIORITY:

- add mouse-controlled time range selection to slider

- CTRL-B to bookmark a position (plot a red vline at that timepoint in all data frames? and/or add that timepoint to file position drop-down combo box), CTRL-F3 and CTRL-F2 to skip forward/back to next/previous bookmark (or select it from list of bookmarked times in file pos combo box)
    - good for skipping back and forth quickly between two (or more) spikes or otherwise interesting regions

- add file pos spin button, and catch the spin button's events (see wx manual pdf page 240) to step through file
    - or just use pgup/pgdown or slider paging

- add scroll wheel support for data frames, for scrolling through data
    - scroll by 40us in spike frame, 1ms in chart frame, 50ms in lfp frame
        - add a .tres attrib to each data frame?

- add vertical zoom controls to all DataFrames

- toggle between garish rainbow colours and normal green

- toggle plot points

- make moving of main spyke window retain existing spatial relations to data frames, instead of resetting to original spacing
    - worked on this for quite a while, couldn't figure it out, had recursive calling problems and stuff
    - ah, I was looking for something like this for a long time: wx.PostEvent(window, event) lets you send any event to any given window. Should try this out...

- goto feature: CTRL+G brings file position spin control into focus where you can enter the time that you want to jump to
    - maybe add ability to choose units (us or ms or s) from a combo box

- parsing progress bar with pause/stop button
    - use threading, so widget draw events aren't blocked during parsing

- load progress bar

- save progress bar

- event detection progress bar with pause/stop button

- matching/ripping progress bar with pause/stop button






------------------------------------
OLDER:

- move simple matplotlib plot() method from Stream class to WaveForm class, that way, you no longer need to pass a trange argument
    - instead of:
        f.highpassstream.plot(chanis=None, trange=(135e6, 135.1e6))
      you'd slice instead:
        f.highpassstream[135e6:135.1e6].plot(chanis=None)
    - would have to add more stuff as attribs to WaveForm class, such as .records and .rts

- low priority: automated template generation
    - need to look into just how complex and slow the (automated) sorting will be
        - can it all be done in pure Python?
    - stick to manual template generation for now

- spike (and lfp? hardly worth it?) data need to be corrected for sample and hold (S+H) delay offsets
    - do this during interpolation as in Surfbawd?

- LFP data need to be corrected for offsets induced by low-pass filters
    - what are the spectral phase and amplitude characteristics of the filters?
    - Hilbert transforms are useful for this?
    - want to do CSDs as well - I guess these don't need to be filter offset corrected, since you're just comparing between lfp chans, not between lfp and spike chans

- can latest wxPy 2.8 reuse numpy data w/o copy?
    - yes, I think so. certainly matplotlib no longer has to do any copying to get data into wxpy, since the interface between them is now pure python, yet still fast

- could eventually add monopole and dipole modelling for 3d localization and to distinguish between pyramidal and stellate cells

- to deal with spike adaptation and attenuation during bursts, for each template, rip not just its mean across the file, but also the biggest and smallest (in terms of something like sum of peak-to-peak voltage across template channels, or variance across channels, or...) spike assigned to that template.
    - or, for each template, plot the distribution of spike sizes for all spikes in that template. For some templates, you might get a skewed distrib in which case: A) you've got a polluted template that needs to be split
                                    B) you need to do something, can't remember what I was gonna write, maybe increase the error thresh for that template?
    - maybe have ability to go from bins in spike size histogram (say its tail, or some weird peak) back to a display of the individual spike(s) that contributed to that bin


- need to be able to select which channels to enable in the template before doing a rip
    - for each template, use mouse controlled bounding box/clicking to pick out significant channels
    - if there's another template nearby in channel space, it's good to also select a few surrounding flat channels to help distinguish the fits of the two templates during the rip



much of this might be outdated, since a Collection class instance now includes all spikes and all templates:

- event collection: a class that represents a specific collection of event times - or maybe be more specific and just call it a spike collection?
    - the event collection class could be results from a spike detection run, members of templates, results from a rip, or any sort of collection of spikes you might generate. Could even be a collection of random times in the recording (noise times) that have nothing to do with spikes
    - event collections should have methods such that you can easily reveal times that two (or more?) collections have or don't have in common (venn diagrams)
        - implement this in GUI using drag and drop? right mouse button drag one collection window onto another, up pops a menu with options like:
            - merge collections
            - copy event times to collection
            - move event times to collection
            - generate new collection of event times in source but not destination
            - generate new collection of event times in destination but not in source
            - generate new collection of overlapping event times (common to both source and destination)
            - plot venn diagram
        - the Python Sets module would be good for this
    - should be able to name event collections, should automatically be named with incrementing numbers
    - the collections themselves would technically only consist of event times in us
        - copies of waveforms wouldn't be stored in spike collections, displaying the waveforms in a collection would require going back to the waveform data, armed with the spike time
    - is spike time in us good enough for uniquely identifying a spike? should we also associate a channel list with it? what exactly is the output of the spike detection algorithm? just spike times, or a list of significant channels as well? Perhaps channel designation should only be allowed in templates. An event/spike is a 54 channel waveform.
    - A template is an event collection plus:
        - channel designation
        - error threshold designation
    - so a template is a subclass of an event collection
    - should ultimately be able to do collections and templates on any of the layouts in the file, not just the main polytrode layout. This means potentially LFP data (lowpassrecords and lowpassmultichanrecords)...

    - maybe "File:New event collection" and "File:New template" items in the main menu, and maybe corresponding main toolbar buttons

    - event collection window GUI:
        - After a round of spike detection, an event collection window pops up. An event collection window has a full channel layout display. It has a combo box that lets you choose an event, labelled by its timepoint and a colour. Choosing it displays the event. To the right of the waveform display, there's a button corresponding to the event, with its timestamp and color in it. The button has a right click context menu that lets you:
            - delete the event
            - remove the event and make a new collection from it
            - remove it and make a new template from it
            - move it to the current template (see below)
        - Or, you can just drag and drop the button to another template or event/collection window to move it to that template/collection
        - dragging the event button off into space removes the event and pops open a new event collection window
        - Clicking the event button toggles its display. Also, there's a spin edit box next to the combo box that allows you to control how many events to display at once. If n > 1, the current event chosen in the combo box is used as the first event, and the n-1 subsequent events are also displayed, and also get their own button next to the waveform display. Each event is given a different colour. Make the color of the first (or only) event always the same, say red.
        - the GUI also has another combo box to the left of the waveform display for selecting the current template to overplot on top of the event(s) in the waveform display. As for events, there's a spin edit box, and buttons representing templates, so you can overplot multiple templates on top of the events, though you normally wouldn't do that much
            - dragging the template buttons off into space would pop open a new template window...

    - template window GUI:
        - pretty much the same as the event collection window, except now events in the combo box on the right are members of the currently selected template. If more than one template is selected, the event combo box and event buttons gray out or disappear completely, and you're in a mode where you're just overplotting and comparing templates.
        - some way of merging currently selected templates
        - some widget for controlling rip error threshold for current template
        - to designate which channels to include in the current template when it comes time to use it for ripping, just click each channel in the waveform display to toggle that channel
- closing a collection or template window just closes its GUI, doesn't delete it. Can bring it back by selecting it from the main window's view menu, or something.

- transparency would be good for overplots

- hard to do?: would be good to have undo/redo for all the collection/template membership manipulations

- what kind of window should we have around the spike time? Does the spike time represent the time of absolute value of peak voltage on the channel with the biggest signal? Then the temporal window around that is -0.25 ms and + 0.75 ms for a total of 1 ms window? I think that's roughly the standard in surfbawd. Temporal window parameters (-ve and +ve offset from spike time) should be a global setting that everything uses, but one that you can change at will (at least when spyke isn't currently doing a rip) to accomodate the display of the occasional long slow spike

- neuron ids should be incrementing integers. When you delete a template, the following templates' ids and colours should remain unchanged, until you hit a toolbar button (or something) to indicate that you want to renumber (and recolour) the whole lot, which will effectively only renumber and recolour those templates following the one that was deleted

- template files
    - contain python syntax that can be eval'd, or config file format, to get you everything you might ever want to know about the template:
        - file (files?) it was generated from
        - member spike times (and their associated files?)
        - date time it was last modified
        - ...
    - store all templates in one file ala surfbawd? or one file per template?
    - store it all in a single SQL database file?
    - or, pickle the whole Collection class instance to file, but also make it possible to export to separate binary spike files (plus the binary .din file)

- do we want to allow templates to be generated from spikes from multiple recordings? this could add annoying complexity, but might be handly for getting enough spikes from those rarely firing neurons - some neurons might fire only during one stimulus type and not the other. Neurons might have opposing preferences, such that you never see them all fire within the same recording

- low probability: in case of electrode drift within a recording, allow user to make executive decision that two templates that are significantly different in voltage+channel space due to drift, yet sufficiently similar to the eye, that they should be assigned the same neuron id (keep their template ids separate?)
    - should there be a distinction between template and neuron ids just in case we want to do something like the above? Maybe the template id should become alphanumeric, with a number followed by a letter, say 12a, 12b, etc.





----------------------------------------------------
DONE:

- move code to /spyke subfolder, make a setup.py in root, keep TODO in root
- how hard will it be to generate highpass, lowpass, chartwindow, and fistogram widgets in wxpython?
    - email wxpython list on displaying time series data.
    - wxpy 2.8 should be faster, doesn't need to copy data, can use numpy data directly?
    - borrow something from MPL?
- need ability to take a spike that's assigned to an existing template and remove it and generate a new template from it
- NOPE: destory data windows instead of hiding them - should be simpler in the end
    - set up config system to, among other things, remember window positions and sizes when you re-open a window, whether within the same session or across sessions
- try making data frames MiniFrames (see manual) instead of passing them the TOOL_WINDOW flag
    - consider making data frames children of the main spyke frame again - maybe this could be done to automatically iconize and activate the data frames when main spyke frame gets the event - yup, this is exactly the case. hooray!
- chart window channel layout is wrong
- arrange data windows so they overlap as little as possible
- end range problem for chart window, allow plotting of nothing...
- remove hard coding in data window positioning
- have a dock mode, where moving one window, whether main spyke frame or any of the data frames, moves all windows the same amount
    - I think all you need to do is give all frames an OnMove method (or something), call all other windows' OnMoves, pass them the event, and then event.Skip()
    - or better yet, make moving the main spyke window always move in dock mode, and moving the dataframes not do so (er, this last one seems hard to do, leave it out)
- make seek move chartwin's center to that position
    - that way you can look at stuff before and after the spike win data
    - also, a centered seek will allow for natural centered zooming in and out in time
- for laying out channels in space, should really be doing a um to uV conversion vertically, and a um to us conversion horizontally. Instead, right now I'm just maintaining vertical and horizontal order, and assuming all chans are equally spaced within those ordered lists
- shade the 1ms (or whatever the spike frame width is) on the chart window with a slightly lighter background than pure black, to indicate what part of the chartwin data you're currently looking at in the spike window
- make spike frame use same colours and chan to colour mapping as chart frame - chart frame is rainbow, spike frame will be similar, but not exactly the same for probes with chans that line up horizontally (like the 3 col probes)
- make spike frame width depend on number of columns in probe, so you get consistent channel width for all probes
- replace default slider position text (which keeps corrupting anyway) with proper spin edit and dedicated text boxes to indicate current position and start and end of recording
- nah: add chan id toggle button to display chan id directly underplotting (or shown next to?) each channel in all the dataframes
    - instead: show timestamp and chan id tooltip on hover
- add faint 0 uV horizontal lines for spike and LFP windows (not necessary for chart win)
    - add faint vertical lines at center of each column in spike window
- add horizontal zoom controls to all DataFrames
- when searching for maxchan, limit search to chans within spatial lockout
      - prevents unrelated distant cells firing at the same time from triggering each other
- add ability to search backwards in time:
    - maybe just slice data in reverse order, Cy loop won't know the difference?
    - would also have to reverse order of block loop, can prolly do this by
      simply making blocksize BS -ve
- BUG: searching for next/last spike with only some channels enabled does weird multiple triggering off of bigger spikes on that channel, and sometimes segfaults if F3/F2 is held down
    - doing the same using search button alternates between two results when some chans are disabled
    - was due to a mistake in indexing into distance matrix in cython code
- create a win32 package installer, or just do python setup.py install, don't really need to bother with the whole py2exe thing, just manually install python, numpy, scipy, wxpy, and mpl on clients
- deal with case where you've got just a .sort file open, and you try adding an event with no wave.data to a template. Prevent user from doing this! Right now it removes the event from the event list and gets as far as trying to update the template mean, at which point it runs into an AssertionError. Need to handle this properly
    - maybe you shouldn't even be able to select an event when its wave.data is unattainable...
- be able to specify time range(s?) within a file to limit spike detection to - this could be useful for limiting detection and template generation to parts of the file during different levels of animal wakefulness, as indicated by the dominant frequencies in the LFP
- specify chans that you want to search for events on. 2 benefits:
    - helps you increase n for a template that rarely fires
    - say you notice a shortage of cells in a certain part of the probe - you want to be sure there aren't any cells there that you've missed
- F3 and F2 to search forward and back one event
- toggle chan selection by Ctrl+click on chan in any of the data frames - this either makes them invisible (but that could cause problems for tooltip when it's looking for the nearest line) or toggles their colour to dark grey or something.
- have a log window at bottom that details everything going on behind the scenes
    - this could simply be an integrated pyshell window (see manual), so you can do things from command line instead of being forced to use the GUI
    - also, use it to examine and mess with internals, including wxpy internals
- keep spyke importable as a library, not just as a standalone program. This way, you can parse files, spike sort, etc directly from interpreter, or neuropy, or any other python project.
- Template.chans should be a property. Every time the user changes the channel selection for a template, you should do Template.chans = Template.get_maxchan() to get the new maxchan from the new set of enabled chans
- introduce a weighted error per template chan, where the template's maxchan is weighted the most and surrounding chans are weighted less as you get further away, maybe a 2D gaussian distance weighting function with standard deviation of one spatial lockout radius
    - use a 2D matrix?, generate it from the actual distances between channels in the probe layout?
    - could also weight points with a gaussian in time, centered on t=0, with stdev=tlock
- Detection deletion:
    - allow if none of the Detector's events have a non-None .template attrib
    - if we allow deletion, maybe session.detections should be a dict instead of a list
- need to handle OnResize in DataFrames like I do in the SortFrame - background needs to be regenerated on every resize event
- in detect_cy.pyx, get_maxchan and set_lockout both have awkwardly long arg lists, maybe make up a struct type whose fields point to all the variables used in this method, and pass the struct to get_maxchan and set_lockout
    - or, just make most of the variables globals, using global keyword
- change lockp from being a counter to holding the absolute timepoint until which the chan is locked out, that way you don't have to decr.
- waveform widgets should display data with the current level of interpolation (surfbawd only ever displayed raw data)
- if matplotlib is used for waveform widgets, will get subpixel rendering and antialiasing for free, which should make interpolated data visibly different from raw data even at low zoom
- randomly sample the srf file to get some (hopefully) representative subset of all the multichannel spike waveforms
- static and dynamic thresholds, independent for each chan, based on stdev or median (or other measures?)
- recreate Detector with current setting whenever user clicks on method or threshold radios
    - clicking on other options can just update the current Detector
    - or better, Detector is updated from other options only when you hit search or F3 or eq'v
- unsorted event list control should have sortable columns: id, maxchan, timestamp.
- use .GetTopLevelParent() from (any?) widget to get a reference to spykeframe, safer than doing a bunch of Parent and GrandParent stuff
    - actually, that only seems to return the frame the widget is in, but then from there you can take the Parent to get tye spykeframe
- tabbing between tree and list ctrl works, but there's something sort of in between that the tab lands on, yet after landing on that something, if you hit up/down, you realize you're actually focused on the event ctrl, just can't tell cuz the current selection for the event list ctrl doesn't highlight where you're in that twilight focus zone
    - i think the twilight zone is actually one or both of the sort panels, cuz the keydown printout happens when you hit a character in the twilight zone
    - MoveAfterInTabOrder and MoveBeforeInTabOrder should help
    - OK, now I've figured it out. It's the stupid .plot_pane that's getting the focus. By deleting the plot_pane, I get rid of the problem. So the trick will be to enforce that the plot_pane can't get focus. Normally, you'd override AcceptsFocusFromKeyboard, but that doesn't work for C++ classes, so you have to do something else. See: http://lists.wxwidgets.org/pipermail/wxpython-users/2008-April/074292.html
    - captured tab keypress in both tree and list controls, use them to transfer focus to the other control
- BUG: splitterwindow doesn't actually set itself to desired size until after you move the mouse for the first time
- make SPACE alone, without CTRL, toggle selection of currently focused item - DONE, but there's an annoying flicker due to the hack around a wx bug, probably can't be eliminated til the wx bug is fixed
- Nick's suggestion: add ability to sort event list by match error, as an alternative to sorting spatially by maxchan. Ie, do a mini-match between the currently selected template or event in the tree (make sure only one item is selected) and all the unsorted events in the event list, and sort the event list by their err. Maybe add an err column to the event list that gets filled in when you ask for a mini-match, and then click the column header to sort by err. Note that many of the entries in the err column will be blank because many events won't have enough similarity in overlapping channels/maxchan distance away to merit even generating an err value.
- try parsing by restoring from .parse files again for speed, especially when it comes to testing...
- rename Session object to Sort object
    - shorter
    - corresponds better to .sort file
    - corresponds better with Sort level (proposed renaming of Rip) in neuropy object hierarchy

SPIKE MODELLING:
        - I think the real answer to most of my fitting problems is that I need to be able to place restraints on the parameters while the fit is running. Does this mean delving into leastsq fortran code? Rewriting leastsq in Cython? Is there another function I should use instead? Should do some searches, maybe mail the scipy list. - solution was to use openopt, which allows all kinds of constraints

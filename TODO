GENERAL:

- interpolation
    - waveform widgets should display data with the current level of interpolation (surfbawd only ever displayed raw data)
    - if matplotlib is used for waveform widgets, will get subpixel rendering and antialiasing for free, which should make interpolated data visibly different from raw data even at low zoom

- spike detection
    - randomly sample the srf file to get some (hopefully) representative subset of all the multichannel spike waveforms

- have a log window at bottom that details everything going on behind the scenes
    - this could simply be an integrated pyshell window, so you can do things from command line instead of being forced to use the GUI
    - also, use it to examine and mess with internals, including wxpy internals

- keep spyke importable as a library, not just as a standalone program. This way, you can parse files, spike sort, etc directly from interpreter, or neuropy, or any other python project.

- low priority: automated template generation
    - need to look into just how complex and slow the (automated) sorting will be
        - can it all be done in pure Python?
    - stick to manual template generation for now

- how hard will it be to generate highpass, lowpass, chartwindow, and fistogram widgets in wxpython?
    - email wxpython list on displaying time series data.
    - wxpy 2.8 should be faster, doesn't need to copy data, can use numpy data directly?
    - borrow something from MPL?

- spike (and lfp?) data need to be corrected for sample and hold (S+H) delay offsets
    - do this during interpolation as in Surfbawd?

- lfp data need to be corrected for offsets induced by low-pass filters
    - what are the spectral phase and amplitude characteristics of the filters?
    - Tim mentioned Hilbert transforms are useful for this
    - want to do CSDs as well - I guess these don't need to be filter offset corrected, since you're just comparing between lfp chans, not between lfp and spike chans

- can latest wxPy 2.8 can reuse numpy data w/o copy?
    - yes, I think so. certainly matplotlib no longer has to do any copying to get data into wxpy, since the interface between them is now pure python, yet still fast

- could eventually add monopole and dipole modelling for 3d localization and to distinguish between pyramidal and stellate cells

- to deal with spike adaptation and attenuation during bursts, for each template, rip not just its mean across the file, but also the biggest and smallest (in terms of something like sum of peak-to-peak voltage across template channels, or variance across channels, or...) spike assigned to that template.
    - or, for each template, plot the distribution of spike sizes for all spikes in that template. For some templates, you might get a skewed distrib in which case: A) you've got a polluted template that needs to be split B) you need
    - maybe have ability to go from bins in spike size histogram (say its tail, or some weird peak) back to a display of the individual spike(s) that contributed to that bin

- need ability to take a spike that's assigned to an existing template and remove it and generate a new template from it
    - this is trivial: when removing a spike from a template, instead of deleting it outright from the display (and returning it back to the list of unprocessed subset of spikes), move it to a sort of temporary visual holding pen, at which point then you can decide if you want to make a new template out of it, or cycle through the existing templates to look for a match

- need to be able to select which channels to enable in the template before doing a rip
    - for each template, use mouse controlled bounding box/clicking to pick out significant channels
    - if there's another template nearby in channel space, it's good to also select a few surrounding flat channels to help distinguish the fits of the two templates during the rip

VERIFICATION:
    - after completing a rip of the whole file, assemble the spike times from all the templates into a single list. Compare it to the list of spike times generated by applying the spike detection algorithm to the whole file. See how the two sets of spike times overlap. Imagine a venn diagram: if there are spike that the detection algorithm found that the MTM algorithm did not find, then you need to examine those spikes. Either: A) you set your error thresh too stringently for the template that should have matched that spike; B)

    - plot autocorrelograms for each template, and cross-correlograms for all template pairs, make sure the bin heights are ~0 for abs(deltaT) < 1ms
    - wasn't there some other related test that we should be doing?
    - Nick had some other kind of idea for verification...


- while building up templates, have ability to do sort of a mini rip of your current templates across the current subset of spikes.
    - this would allow you to quickly increase the number of spikes in each template, and would reveal which spikes in your subset are still very different from any templates you've generated so far, so you can prioritize and focus on those next
    - more importantly, this will aid in sweeping up spikes from those cells that fire a lot and distract you from those that fire rarely
    - a degenerate version of this would be to do a self rip, where you rip across only the set of spikes that are currently members of the template. This would allow you to adjust the error thresh until the self rip just barely returns all of the current members of the template
    - as for a normal rip, you'll first need to set an error thresh for the template
    - as you progress in your template building, you can occasionally do a mini rip and look at the error histogram, to see how well that template separates spikes out from the subset. Should be able to adjust the error thresh such that you get exactly the spikes that are already members


- event collections: general purpose widget/slot that represents a specific collection of event times - or maybe be more specific and just call them spike collections?
    - have a display mode, where you can cycle through the events (spikes) in that collection one by one, or show them 10 at a time or all at once in an overplot, or spread out in a grid fashion (scrollable if need be). Or just a truncated/scrollable list of the spike times in us
    - event collections could be results from a spike detection run, members of templates, results from a rip, or any sort of collection of spikes you might generate. Could even be a collection of random times in the recording (noise times) that have nothing to do with spikes
    - event collections should have methods such that you can easily reveal times that two (or more?) collections have or don't have in common (venn diagrams)
        - implement this in GUI using drag and drop? right mouse button drag one collection widget onto another, up pops a menu with options like:
            - merge collections
            - copy event times to collection
            - generate new collection of event times in source but not destination
            - generate new collection of event times in destination but not in source
            - generate new collection of overlapping event times (common to both source and destination)
            - plot venn diagram
        - the Python Sets module would be good for this
    - should be able to name event collections
    - the collections themselves would technically only consist of event times in us
        - copies of waveforms wouldn't be stored in spike collections, displaying the waveforms in a collection would require going back to the waveform data, armed with the spike time
    - would want to have
    - is spike time in us good enough for uniquely identifying a spike? should we also associate a channel list with it? what exactly is the output of the spike detection algorithm? just a spike time, or a list of significant channels as well? Perhaps channel designation should only be allowed in templates. An event/spike is a 54 channel waveform. A template is an event collection plus:
        - channel designation
        - error threshold designation
    - so a template is a subclass of an event collection


- what kind of window should we have around the spike time? Does the spike time represent the time of absolute value of peak voltage on the channel with the biggest signal? Then the temporal window around that is -0.25 ms and + 0.75 ms for a total of 1 ms window? I think that's roughly the standard in surfbawd. Temporal window parameters (-ve and +ve offset from spike time) should be a global setting that everything uses, but one that you can change at will (at least when spyke isn't currently doing a rip) to accomodate the display of the occasional long slow spike

- dumb question?: should neuron ids be purely increasing ints starting from 0, or should we make 'em alphanum so the can carry more info, such as the chan number of the channel with the biggest signal
    - any extra info should really be stored in a template file, separate from the spike time files

- template files
    - contain python syntax that can be eval'd, or config file format, to get you everything you might ever want to know about the template:
        - file (files?) it was generated from
        - member spike times (and their associated files?)
        - date time it was last modified
        - ...
    - store all templates in one file ala surfbawd? or one file per template?

- do we want to allow templates to be generated from spikes from multiple recordings? this could add annoying complexity, but might be handly for getting enough spikes from those rarely firing neurons - some neurons might fire only during one stimulus type and not the other. Neurons might have opposing preferences, such that you never see them all fire within the same recording

- export stimulus header

- low probability: in case of electrode drift within a recording, allow user to make executive decision that two templates that are significantly different in voltage+channel space due to drift, yet sufficiently similar to the eye, that they should be assigned the same neuron id (keep their template ids separate?)
    - should there be a distinction between template and neuron ids just in case we want to do something like the above?

----------------------------------------------------
SPECIFICS:

- goto feature: CTRL+G pops up a dialog where you can enter the time (in us or ms or s) that you want to jump to

- add parsing progress bar
- move simple matplotlib plot() method from Stream class to WaveForm class, that way, you no longer need to pass a trange argument
    - instead of:
        f.highpassstream.plot(chanis=None, trange=(135e6, 135.1e6))
      you'd slice instead:
        f.highpassstream[135e6:135.1e6].plot(chanis=None)
    - would have to add more stuff as attribs to WaveForm class, such as .records and .rts



----------------------------------------------------
DONE:

- move code to /spyke subfolder, make a setup.py in root, keep TODO in root
